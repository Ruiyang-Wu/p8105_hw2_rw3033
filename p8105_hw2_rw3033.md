p8105_hw2_rw3033
================

# Problem 1

Read the data

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
prob1_df = read_csv(file = "~/Desktop/BIST8105/HW/p8105_hw2_rw3033/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c(".", "NA", ""))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
view(prob1_df)
```

Clean the data Convert the entry variable

``` r
prob1_df = prob1_df |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, 
         route1:route11, entry, vending, entrance_type, ada) |>
  mutate(entry = str_trim(entry), 
         entry = ifelse(entry == "YES", TRUE, FALSE))

str(prob1_df)
```

    ## tibble [1,868 × 19] (S3: tbl_df/tbl/data.frame)
    ##  $ line             : chr [1:1868] "4 Avenue" "4 Avenue" "4 Avenue" "4 Avenue" ...
    ##  $ station_name     : chr [1:1868] "25th St" "25th St" "36th St" "36th St" ...
    ##  $ station_latitude : num [1:1868] 40.7 40.7 40.7 40.7 40.7 ...
    ##  $ station_longitude: num [1:1868] -74 -74 -74 -74 -74 ...
    ##  $ route1           : chr [1:1868] "R" "R" "N" "N" ...
    ##  $ route2           : chr [1:1868] NA NA "R" "R" ...
    ##  $ route3           : chr [1:1868] NA NA NA NA ...
    ##  $ route4           : chr [1:1868] NA NA NA NA ...
    ##  $ route5           : chr [1:1868] NA NA NA NA ...
    ##  $ route6           : chr [1:1868] NA NA NA NA ...
    ##  $ route7           : chr [1:1868] NA NA NA NA ...
    ##  $ route8           : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route9           : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route10          : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route11          : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ entry            : logi [1:1868] TRUE TRUE TRUE TRUE TRUE TRUE ...
    ##  $ vending          : chr [1:1868] "YES" "YES" "YES" "YES" ...
    ##  $ entrance_type    : chr [1:1868] "Stair" "Stair" "Stair" "Stair" ...
    ##  $ ada              : logi [1:1868] FALSE FALSE FALSE FALSE FALSE FALSE ...

``` r
view(prob1_df)
```

Variables: This dataset contains 1,868 rows and 19 columns. Line,
Station Name, Route1 to Route7, vending, Entrance Type are character
variables. Station Latitude, Station Longitude, Route8 to Route11
numeric variables. Entry and ADA are logical variables.

Data Cleaning Steps: The column names were cleaned using
janitor::clean_names() to standardize the format, making them all
lowercase and replacing spaces with underscores. Only the relevant
columns were selected for further analysis: line, station_name,
station_latitude, station_longitude, route1 through route11, entry,
vending, entrance_type, and ada. The entry column, initially containing
“YES” and “NO”, was converted into a logical format (TRUE for “YES” and
FALSE for “NO”).

Tidiness: The dataset is not tidy because it contains NA values, and the
subway routes are inconsistently represented—some are stored as
character (chr) variables while others are stored as numeric (num). This
inconsistency makes it difficult to work with the data in a uniform way,
as all routes should ideally be represented in a single, consistent
format.

Answer questions:

``` r
library(dplyr)

# 1. How many distinct stations are there?
distinct_stations_count = prob1_df |>
  distinct(station_name, line) |>
  nrow()

distinct_stations_count
```

    ## [1] 465

``` r
# 2. How many stations are ADA compliant?
ada_compliant_stations_count = prob1_df |>
  filter(ada == TRUE) |>
  distinct(station_name, line) |>
  nrow()

ada_compliant_stations_count
```

    ## [1] 84

``` r
# 3. Proportion of station entrances / exits without vending
# Total count of stations without vending
total_count_vending_no = prob1_df |>
  filter(vending == "NO") |>
  nrow()

# Total count of station entrances without vending (entry == TRUE)
count_entry_true_without_vending = prob1_df |>
  filter(vending == "NO", entry == TRUE) |>
  nrow()

# Total count of station exits without vending (entry == FALSE)
count_entry_false_without_vending = prob1_df |>
  filter(vending == "NO", entry == FALSE) |>
  nrow()

# Proportion of station entrances without vending (entry == TRUE)
proportion_entrances_without_vending = count_entry_true_without_vending / total_count_vending_no

# Proportion of station exits without vending (entry == FALSE)
proportion_exits_without_vending = count_entry_false_without_vending / total_count_vending_no

# Output the results
proportion_entrances_without_vending
```

    ## [1] 0.3770492

``` r
proportion_exits_without_vending
```

    ## [1] 0.6229508

How many distinct stations are there? Note that stations are identified
both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway;
125st Lenox)? 465 How many stations are ADA compliant? 84 What
proportion of station entrances / exits without vending allow entrance?
P(entrances\|without vending allow entrance) = 0.3770492
P(exits\|without vending allow entrance) = 0.6229508

``` r
library(dplyr)
library(tidyr)
library(stringr)

# Reformat data so that route number and route name are distinct variables
prob1_df_long = prob1_df |>
  mutate(across(route1:route11, as.character)) |>
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_number", 
               values_to = "route_name", 
               values_drop_na = TRUE)

head(prob1_df_long)
```

    ## # A tibble: 6 × 10
    ##   line     station_name station_latitude station_longitude entry vending
    ##   <chr>    <chr>                   <dbl>             <dbl> <lgl> <chr>  
    ## 1 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## 2 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## 3 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## 4 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## 5 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## 6 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## # ℹ 4 more variables: entrance_type <chr>, ada <lgl>, route_number <chr>,
    ## #   route_name <chr>

``` r
# 1. How many distinct stations serve the A train?
distinct_stations_A_train = prob1_df_long |>
  filter(route_name == "A") |>
  distinct(station_name, line) |>
  nrow()

distinct_stations_A_train
```

    ## [1] 60

``` r
# 2. How many of the stations that serve the A train are ADA compliant?
ada_compliant_A_train <- prob1_df_long |>
  filter(route_name == "A", ada == TRUE) |>
  distinct(station_name, line) |>
  nrow()

ada_compliant_A_train
```

    ## [1] 17

How many distinct stations serve the A train? 60 Of the stations that
serve the A train, how many are ADA compliant? 17

# Problem 2

``` r
# Mr. Trash Wheel
library(readxl)
library(dplyr)
library(skimr)
library(tidyr)

# Read the Excel file and specify column types
MrTrashWheel_df = read_excel(
  path = "~/Desktop/BIST8105/HW/p8105_hw2_rw3033/202409 Trash Wheel Collection Data.xlsx", 
  sheet = "Mr. Trash Wheel", 
  na = c("NA", ".", ""))|>
  select(-...15, -...16) |>
  # Use reasonable variable names
  janitor::clean_names() |>
  # Omit rows that do not include dumpster-specific data
  drop_na(dumpster)|>
  # Round the number of sports balls to the nearest integer and convert the result to an integer variable
  mutate(sports_balls = as.integer(round(sports_balls)))|>
  mutate(year = as.numeric(year))|>
  # Add source
  mutate(source = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
str(MrTrashWheel_df)
```

    ## tibble [651 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:651] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:651] "May" "May" "May" "May" ...
    ##  $ year              : num [1:651] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:651], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:651] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:651] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:651] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:651] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:651] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:651] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ plastic_bags      : num [1:651] 584 496 1080 896 368 ...
    ##  $ wrappers          : num [1:651] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : int [1:651] 7 5 6 6 7 5 3 6 6 7 ...
    ##  $ homes_powered     : num [1:651] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ source            : chr [1:651] "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" ...

``` r
# Professor Trash Wheel
library(readxl)
library(dplyr)
library(skimr)
library(tidyr)

# Read the Excel file and specify column types
ProfTrashWheel_df = read_excel(
  path = "~/Desktop/BIST8105/HW/p8105_hw2_rw3033/202409 Trash Wheel Collection Data.xlsx", 
  sheet = "Professor Trash Wheel", 
  na = c("NA", ".", ""))|>
  # Use reasonable variable names
  janitor::clean_names() |>
  # Omit rows that do not include dumpster-specific data
  drop_na(dumpster)|>
  # Add source
  mutate(source = "Professor Trash Wheel")

str(ProfTrashWheel_df)
```

    ## tibble [119 × 14] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:119] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:119] "January" "January" "February" "February" ...
    ##  $ year              : num [1:119] 2017 2017 2017 2017 2017 ...
    ##  $ date              : POSIXct[1:119], format: "2017-01-02" "2017-01-30" ...
    ##  $ weight_tons       : num [1:119] 1.79 1.58 2.32 3.72 1.45 1.71 1.82 2.37 2.64 2.78 ...
    ##  $ volume_cubic_yards: num [1:119] 15 15 18 15 15 15 15 15 15 15 ...
    ##  $ plastic_bottles   : num [1:119] 1950 9540 8350 8590 7830 8210 9830 9240 9540 8230 ...
    ##  $ polystyrene       : num [1:119] 6080 11230 9210 1030 9950 ...
    ##  $ cigarette_butts   : num [1:119] 19700 17600 12000 13000 16000 14000 17000 15000 17000 13000 ...
    ##  $ glass_bottles     : num [1:119] 8 14 19 21 18 23 26 14 28 22 ...
    ##  $ plastic_bags      : num [1:119] 3100 5630 6430 5870 7450 ...
    ##  $ wrappers          : num [1:119] 15600 16700 12400 11030 15340 ...
    ##  $ homes_powered     : num [1:119] 29.8 26.3 38.7 62 24.2 ...
    ##  $ source            : chr [1:119] "Professor Trash Wheel" "Professor Trash Wheel" "Professor Trash Wheel" "Professor Trash Wheel" ...

``` r
# Gwynnda Trash Wheel
library(readxl)
library(dplyr)
library(skimr)
library(tidyr)

# Read the Excel file and specify column types
GwynndaTrashWheel_df = read_excel(
  path = "~/Desktop/BIST8105/HW/p8105_hw2_rw3033/202409 Trash Wheel Collection Data.xlsx", 
  sheet = "Gwynnda Trash Wheel", 
  na = c("NA", ".", ""))|>
  # Use reasonable variable names
  janitor::clean_names() |>
  # Omit rows that do not include dumpster-specific data
  drop_na(dumpster)|>
  mutate(source = "Gwynnda Trash Wheel")

str(GwynndaTrashWheel_df)
```

    ## tibble [263 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:263] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:263] "July" "July" "July" "July" ...
    ##  $ year              : num [1:263] 2021 2021 2021 2021 2021 ...
    ##  $ date              : POSIXct[1:263], format: "2021-07-03" "2021-07-07" ...
    ##  $ weight_tons       : num [1:263] 0.93 2.26 1.62 1.76 1.53 2.06 1.9 2.16 2.6 3.21 ...
    ##  $ volume_cubic_yards: num [1:263] 15 15 15 15 15 15 15 15 15 15 ...
    ##  $ plastic_bottles   : num [1:263] 1200 2000 1800 1000 2100 2400 2700 3000 980 240 ...
    ##  $ polystyrene       : num [1:263] 360 240 270 180 240 360 320 320 180 42 ...
    ##  $ cigarette_butts   : num [1:263] 3400 3900 2900 2100 4000 3900 4200 4000 1800 400 ...
    ##  $ plastic_bags      : num [1:263] 1800 2200 2400 1800 2700 3000 3200 3600 1000 360 ...
    ##  $ wrappers          : num [1:263] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ homes_powered     : num [1:263] 15.5 37.7 27 29.3 25.5 ...
    ##  $ source            : chr [1:263] "Gwynnda Trash Wheel" "Gwynnda Trash Wheel" "Gwynnda Trash Wheel" "Gwynnda Trash Wheel" ...

``` r
# Combine sheets
TidyTrashWheel_df = 
  bind_rows(MrTrashWheel_df, ProfTrashWheel_df, GwynndaTrashWheel_df)
print(TidyTrashWheel_df)
```

    ## # A tibble: 1,033 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,023 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, source <chr>

``` r
str(TidyTrashWheel_df)
```

    ## tibble [1,033 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:1033] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:1033] "May" "May" "May" "May" ...
    ##  $ year              : num [1:1033] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:1033], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:1033] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:1033] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:1033] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:1033] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:1033] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:1033] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ plastic_bags      : num [1:1033] 584 496 1080 896 368 ...
    ##  $ wrappers          : num [1:1033] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : int [1:1033] 7 5 6 6 7 5 3 6 6 7 ...
    ##  $ homes_powered     : num [1:1033] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ source            : chr [1:1033] "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" ...

Paragraph about these data: The dataset (TidyTrashWheel_df) provides a
comprehensive summary of waste collection metrics from the “Mr. Trash
Wheel” initiative. It consists of 15 variables and 1,033 observations,
detailing the amounts of various types of waste collected across
different dates. The columns include information on waste collection
metrics such as weight_tons, volume_cubic_yards, and various categories
of trash items, including plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, and sports_balls. The data also
captures year as numerical data, month as character data, and the exact
date of collection, formatted as POSIXct. Additionally, the source
column, stored as character data, indicates the sheet from which each
row of data originates.

``` r
# Questions
library(dplyr)

# What was the total weight of trash collected by Professor Trash Wheel?
total_weight_professor = TidyTrashWheel_df |>
  filter(source == "Professor Trash Wheel") |>
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))  
  
# What was the total number of cigarette butts collected by Gwynnda in June of 2022?
total_cig_butts_gwynnda = TidyTrashWheel_df |>
  filter(source == "Gwynnda Trash Wheel", year == 2022, month == "June")|>
  summarize(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE)) 

# Print the results
print(total_weight_professor)
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         247.

``` r
print(total_cig_butts_gwynnda)
```

    ## # A tibble: 1 × 1
    ##   total_cigarette_butts
    ##                   <dbl>
    ## 1                 18120

Total weight of trash collected by Professor Trash Wheel: 246.74 tons
Total number of cigarette butts collected by Gwynnda in June of 2022:
1.812^{4}

# Problem 3

``` r
library(dplyr)
library(readr)
library(tidyr)
# Data cleaning
bakers_df = read_csv("~/Desktop/BIST8105/HW/p8105_hw2_rw3033/gbb_datasets/bakers.csv", 
  na = c("NA", ".", ""))|>
  # Use reasonable variable names
  janitor::clean_names()|>
  separate(baker_name, into = c("baker", "baker_lastname"), sep = " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = read_csv("~/Desktop/BIST8105/HW/p8105_hw2_rw3033/gbb_datasets/bakes.csv", 
  na = c("NA", ".", ""))|>
  # Use reasonable variable names
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = read_csv("~/Desktop/BIST8105/HW/p8105_hw2_rw3033/gbb_datasets/results.csv", 
  skip = 2,
  na = c("NA", ".", ""))|>
  # Use reasonable variable names
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Check for bakers in bakes that are not in bakers
bakers_not_in_bakes_1=anti_join(bakes_df, bakers_df, by = c("baker", "series"))
bakers_not_in_bakes_2=anti_join(bakers_df, bakes_df, by = c("baker", "series"))

# Check for bakers in results that are not in bakers
bakers_not_in_results_1=anti_join(bakers_df,results_df, by = c("baker", "series"))
bakers_not_in_results_2=anti_join(results_df,bakers_df, by = c("baker", "series"))
```

``` r
# Rename individual baker in bakes_df
bakes_df = bakes_df |>
  mutate(baker = ifelse(baker == '"Jo"', 'Jo', baker))
```

``` r
# Merge the datasets
merged_df = left_join(results_df, bakes_df, by = c("baker","series", "episode"))

combined_df = left_join(merged_df, bakers_df, by = c("baker","series"))

write_csv(combined_df, "~/Desktop/BIST8105/HW/p8105_hw2_rw3033/gbb_datasets/combined_df.csv")
```

Describe your data cleaning process:

After importing the three datasets, I first checked for missing (NA)
values. I ensured that the baker names were in a consistent format using
janitor::clean_names() and then separated the full names in bakers.csv
into baker and baker_lastname to match the format in bakes.csv and
results.csv. Next, I identified bakers present in bakes.csv and
results.csv but missing in bakers.csv. I found that there was one baker
name with extra quotation marks in bakes.csv, which caused bakers.csv
not to match bakes.csv. I corrected this input mistake. Finally, I
merged the three datasets into combined_df and verified that all rows
were distinct to ensure data integrity.

The final dataset (combined_df) contains all the information, which
results in some duplicated entries. However, I decided to keep it this
way to ensure it includes the most comprehensive information about the
show for future use. If specific details are needed, I can extract the
relevant data as required.

``` r
# Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. 

# Load necessary libraries
library(dplyr)
library(knitr)

# Filter for Seasons 5 through 10 and rows for the Star Baker
star_winner_df = combined_df |>
  filter(series >= 5 & series <= 10) |>
  filter(result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker, result)

# Order by series and episode
star_winner_df = star_winner_df |>
  arrange(series, episode)

# Create a reader-friendly table
star_winner_df = star_winner_df |>
  pivot_wider(
    names_from = series, 
    values_from = baker)

print(star_winner_df)
```

    ## # A tibble: 10 × 8
    ##    episode result     `5`     `6`    `7`       `8`    `9`     `10`    
    ##      <dbl> <chr>      <chr>   <chr>  <chr>     <chr>  <chr>   <chr>   
    ##  1       1 STAR BAKER Nancy   Marie  Jane      Steven Manon   Michelle
    ##  2       2 STAR BAKER Richard Ian    Candice   Steven Rahul   Alice   
    ##  3       3 STAR BAKER Luis    Ian    Tom       Julia  Rahul   Michael 
    ##  4       4 STAR BAKER Richard Ian    Benjamina Kate   Dan     Steph   
    ##  5       5 STAR BAKER Kate    Nadiya Candice   Sophie Kim-Joy Steph   
    ##  6       6 STAR BAKER Chetna  Mat    Tom       Liam   Briony  Steph   
    ##  7       7 STAR BAKER Richard Tamal  Andrew    Steven Kim-Joy Henry   
    ##  8       8 STAR BAKER Richard Nadiya Candice   Stacey Ruby    Steph   
    ##  9       9 STAR BAKER Richard Nadiya Andrew    Sophie Ruby    Alice   
    ## 10      10 WINNER     Nancy   Nadiya Candice   Sophie Rahul   David

Comment on the table: The table presents the Star Baker and Winner
results for Episodes 1 through 10 across Seasons 5 to 10. Each column
represents a season, and each row corresponds to an episode, showing
which baker received the Star Baker title for that particular episode.
The final row displays the overall Winner of each season. Predictable
winners include Nadiya (Season 6) and Candice (Season 7), who had
multiple Star Baker titles. However, there were surprises too: in Season
5, Richard was a strong contender with five Star Baker titles, but Nancy
won in the end. Similarly, Steph dominated Season 10 but lost to David,
making the final results less predictable in some cases.

``` r
# Import, clean, tidy, and organize the viewership data
library(dplyr)
library(readr)
library(tidyr)

viewers_df = read_csv("~/Desktop/BIST8105/HW/p8105_hw2_rw3033/gbb_datasets/viewers.csv", 
  na = c("NA", ".", ""))|>
  # Use reasonable variable names
  janitor::clean_names() |>
  mutate(across(starts_with("series"), ~ round(.x, 2)))
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Show the first 10 rows of this dataset. 
print(head(viewers_df, 10))
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
# What was the average viewership in Season 1?
average_viewership_season_1 = mean(viewers_df$series_1, na.rm = TRUE)

# What was the average viewership in Season 5?
average_viewership_season_5 = mean(viewers_df$series_5, na.rm = TRUE)

# Print the results
print(average_viewership_season_1)
```

    ## [1] 2.77

``` r
print(average_viewership_season_5)
```

    ## [1] 10.039

The average viewership in Season 1: 2.77 The average viewership in
Season 1: 10.039
